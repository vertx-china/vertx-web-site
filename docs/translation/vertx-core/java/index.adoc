= Vert.x Core 文档手册
:toc: left

Vert.x 的核心 Java API 被我们称为 *Vert.x Core*

https://github.com/eclipse/vert.x[Github仓库].

Vert.x Core 提供了下列功能：

* 编写 TCP 客户端和服务端
* 编写支持 WebSocket 的 HTTP 客户端和服务端
* 事件总线
* 共享数据 —— 本地的Map和分布式集群Map
* 周期性、延迟性动作
* 部署和撤销 Verticle 实例
* 数据报套接字
* DNS客户端
* 文件系统访问
* 高可用性
* 本地传输
* 集群

Vert.x Core中的功能相当底层，不包含诸如数据库访问、授权或高层Web应用的功能。
您可以在 *Vert.x ext* （扩展包）（译者注：Vert.x的扩展包是Vert.x的子项目集合，类似 link:../../vertx-web/java/[Web]、 link:../../vertx-web-client/java/[Web Client]、 link:../../#databases[Databases]等）中找到这些功能。

*Vert.x Core* 小而轻，您可以只使用您需要的部分，它可
整体嵌入现存应用中。Vert.x没有强制要求使用特定的方式构
造应用。

Vert.x也支持在其他语言中使用Vert.x Core，
而且在使用诸如 JavaScript 或 Ruby 等语言编写Vert.x代码时，无需直接调用 Java的API；毕竟不同的语言有不同的代码风格，
若强行让 Ruby 开发人员遵循 Java 的代码风格会很怪异，
所以我们根据 Java API 自动生成了适应不同语言代码风格的 API。

From now on we'll just use the word *core* to refer to Vert.x core.

include::override/dependencies.adoc[]

接下来讨论 Vert.x Core 的概念和特性。

include::override/in-the-beginning.adoc[]

== 是流式的吗？

您也许注意到前边的例子里使用了一个 *流式（Fluent）* 的API。

一个流式的API表示将多个方法的调用链在一起。例如：

[source,java]
----
request.response().putHeader("Content-Type", "text/plain").end("some text");
----

这是贯穿 Vert.x API 中的一个通用模式，所以请适应这种代码风格。

流式调用可以让代码更为简洁。当然，
Vert.x并 *不强制* 您用这种方式书写代码，如果您更倾向于用以下非流式编码，
您可以忽略它：

[source,java]
----
HttpServerResponse response = request.response();
response.putHeader("Content-Type", "text/plain");
response.write("some text");
response.end();
----

== Don't call us, we'll call you.

Vert.x 的 API 大部分都是 _事件驱动_ 的。这意味着当您感兴趣的事情发生时，
会以事件的形式发送给您。

以下是一些事件的例子：

* 触发一个计时器
* Socket 收到了一些数据
* 从磁盘中读取了一些数据
* 发生了一个异常
* HTTP 服务器收到了一个请求

Vert.x API调用您提供的 _处理器_ 来处理事件。例如每隔一秒
发送一个事件的计时器：

[source,java]
----
vertx.setPeriodic(1000, id -> {
  // 这个处理器将会每隔一秒被调用一次
  System.out.println("timer fired!");
});
----

又比如收到一个HTTP请求：

[source,java]
----
server.requestHandler(request -> {
  // 服务器每次收到一个HTTP请求时这个处理器将被调用
  request.response().end("hello world!");
});
----

稍后当Vert.x有事件要传给您的处理器时，它会 *异步地* 调用这个处理器。

由此，下面会引入Vert.x中一些重要的概念。

== 不要阻塞我！

Vert.x中的几乎所有API都不会阻塞调用线程，除了个别特例（如以 "Sync" 结尾的某些文件系统操作）。

可以立即提供结果的API会立即返回，否则您需要提供一个处理器（`Handler`）来
接收稍后回调的事件。

因为Vert.x API不会阻塞线程，所以通过Vert.x您可以
只使用少量的线程来处理大量的并发。

当使用传统的阻塞式API做以下操作时，调用线程可能会被阻塞：

* 从 Socket 中读取数据
* 写数据到磁盘
* 发送消息给接收者并等待回复
* 其他很多情况

在上述情况下，线程在等待处理结果时它不能做任何事，此时这些线程并无实际用处。

这意味着如果使用阻塞式API处理大量并发，需要大量线程来防止
应用程序停止运转。

而这些线程使用的内存（例如它们的栈）和线程上下文切换开销很可观。

这意味着，阻塞式的方式对于现代应用程序所需要的并发级别来说是难于扩展的。

== Reactor 模式和 Multi-Reactor 模式

我们前边提过 Vert.x 的 API 都是事件驱动的，当有事件时 Vert.x 会将事件传给处理器来处理。

在多数情况下，Vert.x使用被称为 *Event Loop* 的线程来调用您的处理器。

由于Vert.x或应用程序的代码块中没有阻塞，**Event Loop** 可以在事件到达时
快速地分发到不同的处理器中。

由于没有阻塞，Event Loop 可在短时间内分发大量的事件。
例如，一个单独的 *Event Loop* 可以非常迅速地处理数千个 HTTP 请求。

我们称之为 https://en.wikipedia.org/wiki/Reactor_pattern[Reactor 模式]（译者注：Reactor Pattern 翻译成了 https://zh.wikipedia.org/wiki/%E5%8F%8D%E5%BA%94%E5%99%A8%E6%A8%A1%E5%BC%8F[反应器模式]）。

您之前也许听说过它，例如 Node.js 实现了这种模式。

在一个标准的Reactor实现中，有 *一个独立的 Event Loop* 会循环执行，处理所有
到达的事件并传递给处理器处理。

单一线程的问题在于它在任意时刻只能运行在一个核上，如果您希望单线程
反应器应用（如您的 Node.js 应用）扩展到多核服务器上，则需要启动并且
管理多个不同的进程。

Vert.x的工作方式有所不同。每个 `Vertx` 实例维护的是 *多个Event Loop 线程*。
默认情况下，我们会根据机器上可用的核数量来设置 Event Loop 的数量，您亦可自行设置。

这意味着 Vertx 进程能够在您的服务器上扩展，与 Node.js 不同。

我们将这种模式称为 *Multi-Reactor 模式*（多反应器模式），区别于单线程的 Reactor 模式（反应器模式）。

NOTE: *即使一个 `Vertx` 实例维护了多个 Event Loop，任何一个特定的处理器永远不会被
并发执行。大部分情况下（除了 <<worker_verticles, Worker Verticle>> 以外）它们总是
在同一个 Event Loop 线程中被调用。*

[[golden_rule]]
== 黄金法则：不要阻塞Event Loop

尽管Vert.x 的 API 都是非阻塞式的，且不会阻塞 Event Loop，但是
用户编写的处理器中可能会阻塞 Event Loop。

如果这样做，该 Event Loop 在被阻塞时就不能做任何事情；如果您阻塞了 `Vertx` 实例中的所有
Event Loop，那么您的应用就会完全停止！

所以不要这样做！*这是一个警告!*

这些阻塞做法包括：

* +Thead.sleep()+
* 等待一个锁
* 等待一个互斥信号或监视器（例如同步的代码块）
* 执行一个长时间数据库操作并等待其结果
* 执行一个复杂的计算，占用了可感知的时长
* 在循环语句中长时间逗留

如果上述任何一种情况停止了 Event Loop 并占用了 **显著执行时间** ，那您应该
去面壁（译者注：原文此处为 Naughy Step，英国父母会在家里选择一个角落作为小孩罚站或静坐的地方，被称为 naughty corner 或 naughty step），等待下一步的指示。

所以，什么是 *显著执行时间* ？

您要等多久？它取决于您的应用程序和所需的并发数量。

如果您只有单个 Event Loop，而且您希望每秒处理10000个 HTTP 请求，很明显的是每一个请求
处理时间不可以超过0.1毫秒，所以您不能阻塞任何过多（大于0.1毫秒）的时间。

*这个数学题并不难，将留给读者作为练习。*

如果您的应用程序没有响应，可能这是一个迹象，表明您在某个地方阻塞了Event Loop。为了帮助
您诊断类似问题，若 Vert.x 检测到 Event Loop 有一段时间没有响应，将会自动记录这种警告。
若您在日志中看到类似警告，那么您需要检查您的代码。比如：

----
Thread vertx-eventloop-thread-3 has been blocked for 20458 ms
----

Vert.x 还将提供堆栈跟踪，以精确定位发生阻塞的位置。

如果想关闭这些警告或更改设置，您可以在创建 `Vertx` 对象之前在
`link:../../apidocs/io/vertx/core/VertxOptions.html[VertxOptions]` 中完成此操作。

== Future的异步结果

Vert.x 4使用future承载异步结果。

异步的方法会返回一个 `link:../../apidocs/io/vertx/core/Future.html[Future]` 对象，其包含
_成功_ 或 _失败_ 的异步结果。

我们不能直接操作future的异步结果，而应该设置future的handler；当future执行
完毕，结果可用时，会调用handler进行处理。

[source,java]
----
FileSystem fs = vertx.fileSystem();

Future<FileProps> future = fs.props("/my_file.txt");

future.onComplete((AsyncResult<FileProps> ar) -> {
  if (ar.succeeded()) {
    FileProps props = ar.result();
    System.out.println("File size = " + props.size());
  } else {
    System.out.println("Failure: " + ar.cause().getMessage());
  }
});
----
NOTE: Vert.x 3的API只提供了回调模式；为了减少从Vert.x 3迁移到Vert.x 4的工作量，Vert.x 4为每个异步方法都
保留了回调版本。如上面样例代码的 `props` 方法，提供了
带回调参数的版本 `link:../../apidocs/io/vertx/core/file/FileSystem.html#props-java.lang.String-io.vertx.core.Handler-[props]`

== Future组合

`link:../../apidocs/io/vertx/core/Future.html#compose-java.util.function.Function-[compose]` 方法作用于顺序组合 future：

- 若当前future成功，执行`compose`方法指定的方法，该方法返回新的future；当返回的新future完成时，future组合成功；
- 若当前future失败，则future组合失败。

[source,java]
----
FileSystem fs = vertx.fileSystem();

Future<Void> future = fs
  .createFile("/foo")
  .compose(v -> {
    // createFile文件创建完成后执行
    return fs.writeFile("/foo", Buffer.buffer());
  })
  .compose(v -> {
    // writeFile文件写入完成后执行
    return fs.move("/foo", "/bar");
  });
----

这里例子中，有三个操作被串起来了：

1. 一个文件被创建（`createFile`）
2. 一些东西被写入到文件（`writeFile`）
3. 文件被移走（`move`）

如果这三个步骤全部成功，则最终的 `Future`（`future`）会是成功的；其中
任何一步失败，则最终 `Future` 就是失败的。

除了上述方法， `link:../../apidocs/io/vertx/core/Future.html[Future]` 还提供了更多方法：`map`，`recover`，`otherwise`，以及 `flatMap` （等同 `compose` 方法）。

== Future协作

Vert.x 中的 `link:../../apidocs/io/vertx/core/Future.html[futures]` 支持协调多个Future，
支持并发组合（并行执行多个异步调用）和顺序组合
（依次执行异步调用）。

`link:../../apidocs/io/vertx/core/CompositeFuture.html#all-io.vertx.core.Future-io.vertx.core.Future-[CompositeFuture.all]` 方法接受多个 `Future` 对象作为参数（最多6个，或者传入 `List`）。
当所有的 `Future` 都成功完成，该方法将返回一个 _成功的_ `Future`；当任一个 `Future` 执行失败，则返回一个 _失败的_ `Future`：

[source,java]
----
Future<HttpServer> httpServerFuture = httpServer.listen();

Future<NetServer> netServerFuture = netServer.listen();

CompositeFuture.all(httpServerFuture, netServerFuture).onComplete(ar -> {
  if (ar.succeeded()) {
    // 所有服务器启动完成
  } else {
    // 有一个服务器启动失败
  }
});
----

所有被合并的 `Future` 中的操作同时运行。当组合的处理操作完成时，该方法返回的 `Future` 上绑定的处理器（[`Handler`](https://vertx.io/docs/apidocs/io/vertx/core/Handler.html)）会被调用。
只要有一个操作失败（其中的某一个 `Future` 的状态被标记成失败），
则返回的 `Future` 会被标记为失败。如果所有的操作都成功，
则返回的 `Future` 将会成功完成。

您可以传入一个 `Future` 列表（可能为空）：

[source,java]
----
CompositeFuture.all(Arrays.asList(future1, future2, future3));
----

`all` 方法的合并会 _等待_ 所有的 Future 成功执行（或任一失败），而`any` 方法的合并
会 _等待_ 第一个成功执行的Future。`link:../../apidocs/io/vertx/core/CompositeFuture.html#any-io.vertx.core.Future-io.vertx.core.Future-[CompositeFuture.any]` 方法接受多个 `Future`
作为参数（最多6个，或传入 `List`）。当任意一个 `Future` 成功得到结果，则该 `Future` 成功；
当所有的 `Future` 都执行失败，则该 `Future` 失败。

[source,java]
----
CompositeFuture.any(future1, future2).onComplete(ar -> {
  if (ar.succeeded()) {
    // 至少一个成功
  } else {
    // 所有的都失败
  }
});
----

它也可使用 `Future` 列表传参：

[source,java]
----
CompositeFuture.any(Arrays.asList(f1, f2, f3));
----

`join` 方法的合并会 _等待_ 所有的 `Future` 完成，无论成败。
`link:../../apidocs/io/vertx/core/CompositeFuture.html#join-io.vertx.core.Future-io.vertx.core.Future-[CompositeFuture.join]` 方法接受多个 `Future` 作为参数（最多6个），并将结果归并成一个 `Future` 。
当全部 `Future` 成功执行完成，得到的 `Future` 是成功状态的；当至少一个 `Future` 执行失败时，得到的 `Future` 是
失败状态的。

[source,java]
----
CompositeFuture.join(future1, future2, future3).onComplete(ar -> {
  if (ar.succeeded()) {
    // 所有都成功
  } else {
    // 全部完成（无论成功还是失败），且至少一个失败
  }
});
----

它也可使用 `Future` 列表传参：

[source,java]
----
CompositeFuture.join(Arrays.asList(future1, future2, future3));
----

=== 兼容CompletionStage

JDK的 `CompletionStage` 接口用于组合异步操作，
Vert.x的 `Future` API可兼容`CompletionStage`。

我们可以用 `link:../../apidocs/io/vertx/core/Future.html#toCompletionStage--[toCompletionStage]` 方法将Vert.x的 `Future` 对象转为 `CompletionStage` 对象，如：

[source,java]
----
Future<String> future = vertx.createDnsClient().lookup("vertx.io");
future.toCompletionStage().whenComplete((ip, err) -> {
  if (err != null) {
    System.err.println("Could not resolve vertx.io");
    err.printStackTrace();
  } else {
    System.out.println("vertx.io => " + ip);
  }
});
----

相应地，可使用 `link:../../apidocs/io/vertx/core/Future.html#fromCompletionStage-java.util.concurrent.CompletionStage-[Future.fromCompletionStage]` 方法将 `CompletionStage` 对象转为Vert.x的 `Future` 对象。
`Future.fromCompletionStage` 有两个重载方法：

. 第一个重载方法只接收一个 `CompletionStage` 参数，会在执行 `CompletionStage` 实例的线程中调用 `Future` 的方法；
. 第二个重载方法额外多接收一个 `link:../../apidocs/io/vertx/core/Context.html[Context]` 参数，会在Vert.x的Context中调用 `Future` 的方法。

IMPORTANT: 由于Vert.x的 `Future` 通常会与Vert.x的代码、库以及客户端等一起使用，为了与Vert.x的线程模型更好地配合，
大部分场景下应使用`Future.fromCompletionStage(CompletionStage, Context)`方法。

下面的例子展示了如何将 `CompletionStage` 对象转为Vert.x的 `Future` 对象，这里选择使用Vert.x的Context执行:

[source,java]
----
Future.fromCompletionStage(completionStage, vertx.getOrCreateContext())
  .flatMap(str -> {
    String key = UUID.randomUUID().toString();
    return storeInDb(key, str);
  })
  .onSuccess(str -> {
    System.out.println("We have a result: " + str);
  })
  .onFailure(err -> {
    System.err.println("We have a problem");
    err.printStackTrace();
  });
----

== Verticles

Vert.x 通过开箱即用的方式提供了一个简单便捷的、可扩展的、类似 https://en.wikipedia.org/wiki/Actor_model[Actor Model] 的部署和并发模型机制。
您可以用此模型机制来保管您自己的代码组件。

*这个模型是可选的，Vert.x
并不强制使用这种方式创建应用程序。*

这个模型并不是严格的 Actor 模式实现，但它确实有相似之处，
特别是在并发、扩展性和部署等方面。

使用该模型，需要将应用代码编写成多个 *Verticle*。

Verticle 是由 Vert.x 部署和运行的代码块。默认情况一个 Vert.x 实例维护了N个 Event Loop 线程
（默认情况下N = CPU核数 x 2）。Verticle 实例可使用任意 Vert.x 支持的编程语言编写，而且
一个简单的应用程序也可以包含多种语言编写的 Verticle。

您可以将 Verticle 想成 http://en.wikipedia.org/wiki/Actor_model[Actor Model] 中的 Actor。

一个应用程序通常是由在同一个 Vert.x 实例中同时运行的许多 Verticle 实例组合而成。
不同的 Verticle 实例通过向 <<event_bus, Event Bus>> 上发送消息来相互通信。

include::override/verticles.adoc[]

=== Verticle 种类

这儿有两种 Verticle：

Standard Verticles:: 这是最常用的一类 Verticle —— 它们永远运行在 Event Loop 线程上。
更多讨论详见稍后的章节。
Worker Verticles:: 这类 Verticle 会运行在 Worker Pool 中的线程上。一个实例绝对不会被
多个线程同时执行。

=== Standard verticles

当 Standard Verticle 被创建时，它会被分派给一个 Event Loop 线程，并在这个 Event Loop 中执行它的 `start` 方法。
当您在一个 Event Loop 上调用了 Core API 中的方法并传入了处理器时，Vert.x
将保证用与调用该方法时相同的 Event Loop 来执行这些处理器。

这意味着我们可以保证您的 Verticle 实例中 *所有的代码都是在相同Event Loop中执行*（只要
您不创建自己的线程来调用它！）

同样意味着您可以将您的应用中的所有代码用单线程方式编写，让 Vert.x 去考虑线程
和扩展问题。您不用再考虑 synchronized 和 volatile 的问题，也可以避免传统的
多线程应用经常会遇到的竞态条件和死锁的问题。

[[worker_verticles]]
=== Worker verticles

Worker Verticle 和 Standard Verticle 很像，但它并不是由一个 Event Loop 来执行，
而是由Vert.x中的 Worker Pool 中的线程执行。

Worker Verticle 设计用于调用阻塞式代码，它不会阻塞任何 Event Loop。

如果您不想使用 Worker Verticle 来运行阻塞式代码，您还可以在一个
Event Loop中直接使用 <<blocking_code, 内联阻塞式代码>>

您需要通过 `link:../../apidocs/io/vertx/core/DeploymentOptions.html#setWorker-boolean-[setWorker] 方法来将 Verticle 部署成一个 Worker Verticle：

[source,java]
----
DeploymentOptions options = new DeploymentOptions().setWorker(true);
vertx.deployVerticle("com.mycompany.MyOrderProcessorVerticle", options);
----

在 Vert.x 中，Worker Verticle 实例绝对不会同时被多个线程执行，但它可以
在不同时间由不同线程执行。

=== 编程方式部署Verticle

部署Verticle可以使用任意一个 `link:../../apidocs/io/vertx/core/Vertx.html#deployVerticle-io.vertx.core.Verticle-[deployVerticle]` 方法，并传入一个 Verticle
名称或Verticle 实例。

NOTE: 通过 Verticle *实例* 来部署 Verticle 仅限Java语言。

[source,java]
----
Verticle myVerticle = new MyVerticle();
vertx.deployVerticle(myVerticle);
----

您同样可以指定 Verticle 的 *名称* 来部署它。

这个 Verticle 的名称会用于查找实例化 Verticle
的特定 `link:../../apidocs/io/vertx/core/spi/VerticleFactory.html[VerticleFactory]`。

不同的 Verticle Factory 可用于实例化不同语言的 Verticle，也可用于其他
目的，例如加载服务、运行时从Maven中获取Verticle实例等。

因此可以部署任何使用Vert.x支持的语言编写的Verticle。

下面的例子展示了如何部署多个不同语言编写的 Verticle ：

[source,java]
----
vertx.deployVerticle("com.mycompany.MyOrderProcessorVerticle");

// 部署JavaScript的Verticle
vertx.deployVerticle("verticles/myverticle.js");

// 部署Ruby的Verticle
vertx.deployVerticle("verticles/my_verticle.rb");
----

=== Verticle名称到Factory的映射规则

使用名称部署Verticle时，会通过名称来选择一个用于实例化 Verticle
的 Verticle Factory。

Verticle 名称可以增加一个以冒号结尾的前缀，这个前缀用于查找Factory，如：

----
js:foo.js // 使用JavaScript的Factory
groovy:com.mycompany.SomeGroovyCompiledVerticle // 用Groovy的Factory
service:com.mycompany:myorderservice // 用Service的Factory
----

如果不指定前缀，Vert.x将根据Verticle名称的后缀来查找对应Factory，如：

----
foo.js // 将使用JavaScript的Factory
SomeScript.groovy // 将使用Groovy的Factory
----

若前缀后缀都没指定，Vert.x将假定Verticle名称是一个Java 全限定类名（FQCN），并尝试
实例化它。

=== 如何定位Verticle Factory？

大部分Verticle Factory会从 classpath 中加载，并在 Vert.x 启动时注册。

您同样可以使用编程的方式去注册或注销Verticle Factory：通过 `link:../../apidocs/io/vertx/core/Vertx.html#registerVerticleFactory-io.vertx.core.spi.VerticleFactory-[registerVerticleFactory]` 方法
和 `link:../../apidocs/io/vertx/core/Vertx.html#unregisterVerticleFactory-io.vertx.core.spi.VerticleFactory-[unregisterVerticleFactory]` 方法。

=== 等待部署完成

Verticle是异步部署的，换而言之，可能在 `deploy` 方法调用返回后一段时间才会完成部署。

如果您想要在部署完成时收到通知，则可以指定一个完成处理器：

[source,java]
----
vertx.deployVerticle("com.mycompany.MyOrderProcessorVerticle", res -> {
  if (res.succeeded()) {
    System.out.println("Deployment id is: " + res.result());
  } else {
    System.out.println("Deployment failed!");
  }
});
----

如果部署成功，这个完成处理器的结果中将会包含部署ID的字符串。

这个部署ID可以用于撤销部署。

=== 撤销Verticle

我们可以通过 `link:../../apidocs/io/vertx/core/Vertx.html#undeploy-java.lang.String-[undeploy]` 方法来撤销部署好的 Verticle。

撤销操作也是异步的，因此若您想要在撤销完成后收到通知，则可以指定另一个完成处理器：

[source,java]
----
vertx.undeploy(deploymentID, res -> {
  if (res.succeeded()) {
    System.out.println("Undeployed ok");
  } else {
    System.out.println("Undeploy failed!");
  }
});
----

=== 设置 Verticle 实例数量

使用名称部署 Verticle 时，可以指定需要部署的 Verticle
实例的数量。

[source,java]
----
DeploymentOptions options = new DeploymentOptions().setInstances(16);
vertx.deployVerticle("com.mycompany.MyOrderProcessorVerticle", options);
----

这个功能对于跨多核扩展时很有用。例如，您有一个带Web服务的Verticle需要部署
在多核的机器上，您可以部署多个实例来利用所有的核。

include::override/verticle-configuration.adoc[]

=== 高可用性

Verticle可以启用高可用方式（HA）部署。在这种方式下，当其中一个部署在
Vert.x 实例中的 Verticle 突然挂掉，这个 Verticle 可以在集群环境中的另一个 Vert.x 实例中重新部署。

若要启用高可用方式运行一个 Verticle，仅需要追加 `-ha` 参数：

[source]
----
vertx run my-verticle.js -ha
----

当启用高可用方式时，不需要追加 `-cluster` 参数。

关于高可用的功能和配置的更多细节可
参考 <<high_avalibability_and_fail_over, 高可用和故障转移>>


=== 从命令行运行Verticle

You can use Vert.x directly in your Maven or Gradle projects in the normal way by adding a dependency to the Vert.x
core library and hacking from there.

However you can also run Vert.x verticles directly from the command line if you wish.

To do this you need to download and install a Vert.x distribution, and add the `bin` directory of the installation
to your `PATH` environment variable. Also make sure you have a Java 8 JDK on your `PATH`.

NOTE: The JDK is required to support on the fly compilation of Java code.

You can now run verticles by using the `vertx run` command. Here are some examples:

----
# Run a JavaScript verticle
vertx run my_verticle.js

# Run a Ruby verticle
vertx run a_n_other_verticle.rb

# Run a Groovy script verticle, clustered
vertx run FooVerticle.groovy -cluster
----

You can even run Java source verticles without compiling them first!

----
vertx run SomeJavaSourceFile.java
----

Vert.x will compile the Java source file on the fly before running it. This is really useful for quickly
prototyping verticles and great for demos. No need to set-up a Maven or Gradle build first to get going!

For full information on the various options available when executing `vertx` on the command line,
type `vertx` at the command line.

=== Causing Vert.x to exit

Threads maintained by Vert.x instances are not daemon threads so they will prevent the JVM from exiting.

If you are embedding Vert.x and you have finished with it, you can call `link:../../apidocs/io/vertx/core/Vertx.html#close--[close]` to close it
down.

This will shut-down all internal thread pools and close other resources, and will allow the JVM to exit.

=== The Context object

When Vert.x provides an event to a handler or calls the start or stop methods of a
`link:../../apidocs/io/vertx/core/Verticle.html[Verticle]`, the execution is associated with a `Context`. Usually a context is an
*event-loop context* and is tied to a specific event loop thread. So executions for that context always occur
on that exact same event loop thread. In the case of worker verticles and running inline blocking code a
worker context will be associated with the execution which will use a thread from the worker thread pool.

To retrieve the context, use the `link:../../apidocs/io/vertx/core/Vertx.html#getOrCreateContext--[getOrCreateContext]` method:

[source, java]
----
Context context = vertx.getOrCreateContext();
----

If the current thread has a context associated with it, it reuses the context object. If not a new instance of
context is created. You can test the _type_ of context you have retrieved:

[source, java]
----
Context context = vertx.getOrCreateContext();
if (context.isEventLoopContext()) {
  System.out.println("Context attached to Event Loop");
} else if (context.isWorkerContext()) {
  System.out.println("Context attached to Worker Thread");
} else if (! Context.isOnVertxThread()) {
  System.out.println("Context not attached to a thread managed by vert.x");
}
----

When you have retrieved the context object, you can run code in this context asynchronously. In other words,
you submit a task that will be eventually run in the same context, but later:

[source, java]
----
vertx.getOrCreateContext().runOnContext( (v) -> {
  System.out.println("This will be executed asynchronously in the same context");
});
----

When several handlers run in the same context, they may want to share data. The context object offers methods to
store and retrieve data shared in the context. For instance, it lets you pass data to some action run with
`link:../../apidocs/io/vertx/core/Context.html#runOnContext-io.vertx.core.Handler-[runOnContext]`:

[source, java]
----
final Context context = vertx.getOrCreateContext();
context.put("data", "hello");
context.runOnContext((v) -> {
  String hello = context.get("data");
});
----

The context object also let you access verticle configuration using the `link:../../apidocs/io/vertx/core/Context.html#config--[config]`
method. Check the <<Passing configuration to a verticle>> section for more details about this configuration.

=== Executing periodic and delayed actions

It's very common in Vert.x to want to perform an action after a delay, or periodically.

In standard verticles you can't just make the thread sleep to introduce a delay, as that will block the event loop thread.

Instead you use Vert.x timers. Timers can be *one-shot* or *periodic*. We'll discuss both

==== One-shot Timers

A one shot timer calls an event handler after a certain delay, expressed in milliseconds.

To set a timer to fire once you use `link:../../apidocs/io/vertx/core/Vertx.html#setTimer-long-io.vertx.core.Handler-[setTimer]` method passing in the delay and a handler

[source,java]
----
long timerID = vertx.setTimer(1000, id -> {
  System.out.println("And one second later this is printed");
});

System.out.println("First this is printed");
----

The return value is a unique timer id which can later be used to cancel the timer. The handler is also passed the timer id.

==== Periodic Timers

You can also set a timer to fire periodically by using `link:../../apidocs/io/vertx/core/Vertx.html#setPeriodic-long-io.vertx.core.Handler-[setPeriodic]`.

There will be an initial delay equal to the period.

The return value of `setPeriodic` is a unique timer id (long). This can be later used if the timer needs to be cancelled.

The argument passed into the timer event handler is also the unique timer id:

Keep in mind that the timer will fire on a periodic basis. If your periodic treatment takes a long amount of time to proceed,
your timer events could run continuously or even worse : stack up.

In this case, you should consider using `link:../../apidocs/io/vertx/core/Vertx.html#setTimer-long-io.vertx.core.Handler-[setTimer]` instead. Once your treatment has
finished, you can set the next timer.

[source,java]
----
long timerID = vertx.setPeriodic(1000, id -> {
  System.out.println("And every second this is printed");
});

System.out.println("First this is printed");
----

==== Cancelling timers

To cancel a periodic timer, call `link:../../apidocs/io/vertx/core/Vertx.html#cancelTimer-long-[cancelTimer]` specifying the timer id. For example:

[source,java]
----
vertx.cancelTimer(timerID);
----

==== Automatic clean-up in verticles

If you're creating timers from inside verticles, those timers will be automatically closed
when the verticle is undeployed.

=== Verticle worker pool

Verticles use the Vert.x worker pool for executing blocking actions, i.e `link:../../apidocs/io/vertx/core/Context.html#executeBlocking-io.vertx.core.Handler-boolean-io.vertx.core.Handler-[executeBlocking]` or
worker verticle.

A different worker pool can be specified in deployment options:

[source,java]
----
vertx.deployVerticle("the-verticle", new DeploymentOptions().setWorkerPoolName("the-specific-pool"));
----

[[event_bus]]
include::eventbus.adoc[]

include::override/json.adoc[]

include::json-pointers.adoc[]

include::buffers.adoc[]

include::net.adoc[]

include::http.adoc[]

include::shareddata.adoc[]

include::filesystem.adoc[]

include::datagrams.adoc[]

include::dns.adoc[]

[[streams]]
include::streams.adoc[]

include::parsetools.adoc[]

== Thread safety

Most Vert.x objects are safe to access from different threads. _However_ performance is optimised when they are
accessed from the same context they were created from.

For example if you have deployed a verticle which creates a `link:../../apidocs/io/vertx/core/net/NetServer.html[NetServer]` which provides
`link:../../apidocs/io/vertx/core/net/NetSocket.html[NetSocket]` instances in it's handler, then it's best to always access that socket instance
from the event loop of the verticle.

If you stick to the standard Vert.x verticle deployment model and avoid sharing objects between verticles then this
should be the case without you having to think about it.

[[blocking_code]]
== Running blocking code

In a perfect world, there will be no war or hunger, all APIs will be written asynchronously and bunny rabbits will
skip hand-in-hand with baby lambs across sunny green meadows.

*But... the real world is not like that. (Have you watched the news lately?)*

Fact is, many, if not most libraries, especially in the JVM ecosystem have synchronous APIs and many of the methods are
likely to block. A good example is the JDBC API - it's inherently synchronous, and no matter how hard it tries, Vert.x
cannot sprinkle magic pixie dust on it to make it asynchronous.

We're not going to rewrite everything to be asynchronous overnight so we need to provide you a way to use "traditional"
blocking APIs safely within a Vert.x application.

As discussed before, you can't call blocking operations directly from an event loop, as that would prevent it
from doing any other useful work. So how can you do this?

It's done by calling `link:../../apidocs/io/vertx/core/Vertx.html#executeBlocking-io.vertx.core.Handler-boolean-io.vertx.core.Handler-[executeBlocking]` specifying both the blocking code to execute and a
result handler to be called back asynchronous when the blocking code has been executed.

[source,java]
----
vertx.executeBlocking(promise -> {
  // Call some blocking API that takes a significant amount of time to return
  String result = someAPI.blockingMethod("hello");
  promise.complete(result);
}, res -> {
  System.out.println("The result is: " + res.result());
});
----

WARNING: Blocking code should block for a reasonable amount of time (i.e no more than a few seconds). Long blocking operations
or polling operations (i.e a thread that spin in a loop polling events in a blocking fashion) are precluded.
When the blocking operation lasts more than the 10 seconds, a message will be printed on the console by the
blocked thread checker. Long blocking operations should use a dedicated thread managed by the application,
which can interact with verticles using the event-bus or `link:../../apidocs/io/vertx/core/Context.html#runOnContext-io.vertx.core.Handler-[runOnContext]`


By default, if executeBlocking is called several times from the same context (e.g. the same verticle instance) then
the different executeBlocking are executed _serially_ (i.e. one after another).

If you don't care about ordering you can call `link:../../apidocs/io/vertx/core/Vertx.html#executeBlocking-io.vertx.core.Handler-boolean-io.vertx.core.Handler-[executeBlocking]`
specifying `false` as the argument to `ordered`. In this case any executeBlocking may be executed in parallel
on the worker pool.

An alternative way to run blocking code is to use a <<worker_verticles, worker verticle>>

A worker verticle is always executed with a thread from the worker pool.

By default blocking code is executed on the Vert.x worker pool, configured with `link:../../apidocs/io/vertx/core/VertxOptions.html#setWorkerPoolSize-int-[setWorkerPoolSize]`.

Additional pools can be created for different purposes:

[source,java]
----
WorkerExecutor executor = vertx.createSharedWorkerExecutor("my-worker-pool");
executor.executeBlocking(promise -> {
  // Call some blocking API that takes a significant amount of time to return
  String result = someAPI.blockingMethod("hello");
  promise.complete(result);
}, res -> {
  System.out.println("The result is: " + res.result());
});
----

The worker executor must be closed when it's not necessary anymore:

[source,java]
----
executor.close();
----

When several workers are created with the same name, they will share the same pool. The worker pool is destroyed
when all the worker executors using it are closed.

When an executor is created in a Verticle, Vert.x will close it automatically for you when the Verticle
is undeployed.

Worker executors can be configured when created:

[source,java]
----
int poolSize = 10;

// 2 minutes
long maxExecuteTime = 2;
TimeUnit maxExecuteTimeUnit = TimeUnit.MINUTES;

WorkerExecutor executor = vertx.createSharedWorkerExecutor("my-worker-pool", poolSize, maxExecuteTime, maxExecuteTimeUnit);
----

NOTE: the configuration is set when the worker pool is created

== Metrics SPI

By default Vert.x does not record any metrics. Instead it provides an SPI for others to implement which can be added
to the classpath. The metrics SPI is an advanced feature which allows implementers to capture events from Vert.x in
order to gather metrics. For more information on this, please consult the
`link:../../apidocs/io/vertx/core/spi/metrics/VertxMetrics.html[API Documentation]`.

You can also specify a metrics factory programmatically if embedding Vert.x using
`link:../../apidocs/io/vertx/core/metrics/MetricsOptions.html#setFactory-io.vertx.core.spi.VertxMetricsFactory-[setFactory]`.

== The 'vertx' command line

The `vertx` command is used to interact with Vert.x from the command line. It's main use is to run Vert.x verticles.
To do this you need to download and install a Vert.x distribution, and add the `bin` directory of the installation
to your `PATH` environment variable. Also make sure you have a Java 8 JDK on your `PATH`.

NOTE: The JDK is required to support on the fly compilation of Java code.

=== Run verticles

You can run raw Vert.x verticles directly from the command line using `vertx run`. Here is a couple of examples of
the `run` _command_:

[source]
----
vertx run my-verticle.js                                 (1)
vertx run my-verticle.groovy                             (2)
vertx run my-verticle.rb                                 (3)

vertx run io.vertx.example.MyVerticle                    (4)
vertx run io.vertx.example.MVerticle -cp my-verticle.jar (5)

vertx run MyVerticle.java                                (6)
----
1. Deploys a JavaScript verticle
2. Deploys a Groovy verticle
3. Deploys a Ruby verticle
4. Deploys an already compiled Java verticle. Classpath root is the current directory
5. Deploys a verticle packaged in a Jar, the jar need to be in the classpath
6. Compiles the Java source and deploys it

As you can see in the case of Java, the name can either be the fully qualified class name of the verticle, or
you can specify the Java Source file directly and Vert.x compiles it for you.

You can also prefix the verticle with the name of the language implementation to use. For example if the verticle is
a compiled Groovy class, you prefix it with `groovy:` so that Vert.x knows it's a Groovy class not a Java class.

[source]
----
vertx run groovy:io.vertx.example.MyGroovyVerticle
----

The `vertx run` command can take a few optional parameters, they are:

* `-options <options>` - Provides the Vert.x options.
`options` is the name of a JSON file that represents the Vert.x options, or a JSON string. This is optional.
* `-conf <config>` - Provides some configuration to the verticle.
`config` is the name of a JSON file that represents the configuration for the verticle, or a JSON string. This is optional.
* `-cp <path>` - The path on which to search for the verticle and any other resources used by the verticle. This
defaults to `.` (current directory). If your verticle references other scripts, classes or other resources
(e.g. jar files) then make sure these are on this path. The path can contain multiple path entries separated by
`:` (colon) or `;` (semi-colon) depending on the operating system. Each path entry can be an absolute or relative
path to a directory containing scripts, or absolute or relative filenames for jar or zip files. An example path
might be `-cp classes:lib/otherscripts:jars/myjar.jar:jars/otherjar.jar`. Always use the path to reference any
resources that your verticle requires. Do **not** put them on the system classpath as this can cause isolation
issues between deployed verticles.
* `-instances <instances>`  - The number of instances of the verticle to instantiate. Each verticle instance is
strictly single threaded so to scale your application across available cores you might want to deploy more than
one instance. If omitted a single instance will be deployed.
* `-worker` - This option determines whether the verticle is a worker verticle or not.
* `-cluster` -  This option determines whether the Vert.x instance will attempt to form a cluster with other Vert.x
instances on the network. Clustering Vert.x instances allows Vert.x to form a distributed event bus with
other nodes. Default is `false` (not clustered).
* `-cluster-port` - If the `cluster` option has also been specified then this determines which port will be bound for
cluster communication with other Vert.x instances. Default is `0` - which means '_choose a free random port_'. You
don't usually need to specify this parameter unless you really need to bind to a specific port.
* `-cluster-host` - If the `cluster` option has also been specified then this determines which host address will be
bound for cluster communication with other Vert.x instances. If not set, the clustered eventbus tries to bind to the
same host as the underlying cluster manager. As a last resort, an address will be picked among the available network
interfaces.
* `-cluster-public-port` - If the `cluster` option has also been specified then this determines which port will be advertised for
cluster communication with other Vert.x instances. Default is `-1`, which means same as `cluster-port`.
* `-cluster-public-host` - If the `cluster` option has also been specified then this determines which host address will be advertised for
cluster communication with other Vert.x instances. If not specified, Vert.x uses the value of `cluster-host`.
* `-ha` - if specified the verticle will be deployed as  high availability (HA) deployment. See related section
for more details
* `-quorum` - used in conjunction with `-ha`. It specifies the minimum number of nodes in the cluster for any _HA
deploymentIDs_ to be active. Defaults to 0.
* `-hagroup` - used in conjunction with `-ha`. It specifies the HA group this node will join. There can be
multiple HA groups in a cluster. Nodes will only failover to other nodes in the same group. The default value is `
+++__DEFAULT__+++`

You can also set system properties using: `-Dkey=value`.

Here are some more examples:

Run a JavaScript verticle server.js with default settings
[source]
----
vertx run server.js
----

Run 10 instances of a pre-compiled Java verticle specifying classpath
[source]
----
vertx run com.acme.MyVerticle -cp "classes:lib/myjar.jar" -instances 10
----

Run 10 instances of a Java verticle by source _file_
[source]
----
vertx run MyVerticle.java -instances 10
----

Run 20 instances of a ruby worker verticle
[source]
----
vertx run order_worker.rb -instances 20 -worker
----

Run two JavaScript verticles on the same machine and let them cluster together with each other and any other servers
on the network
[source]
----
vertx run handler.js -cluster
vertx run sender.js -cluster
----

Run a Ruby verticle passing it some config
[source]
----
vertx run my_verticle.rb -conf my_verticle.conf
----
Where `my_verticle.conf` might contain something like:

[source, json]
----
{
"name": "foo",
"num_widgets": 46
}
----

The config will be available inside the verticle via the core API.

When using the high-availability feature of vert.x you may want to create a _bare_ instance of vert.x. This
instance does not deploy any verticles when launched, but will receive a verticle if another node of the cluster
dies. To create a _bare_ instance, launch:

[source]
----
vertx bare
----

Depending on your cluster configuration, you may have to append the `cluster-host` and `cluster-port` parameters.

=== Executing a Vert.x application packaged as a fat jar

A _fat jar_ is an executable jar embedding its dependencies. This means you don't have to have Vert.x pre-installed
on the machine on which you execute the jar. Like any executable Java jar it can be executed with.

[source]
----
java -jar my-application-fat.jar
----

There is nothing really Vert.x specific about this, you could do this with any Java application

You can either create your own main class and specify that in the manifest, but it's recommended that you write your
code as verticles and use the Vert.x `link:../../apidocs/io/vertx/core/Launcher.html[Launcher]` class (`io.vertx.core.Launcher`) as your main
class. This is the same main class used when running Vert.x at the command line and therefore allows you to
specify command line arguments, such as `-instances` in order to scale your application more easily.

To deploy your verticle in a _fatjar_ like this you must have a _manifest_ with:

* `Main-Class` set to `io.vertx.core.Launcher`
* `Main-Verticle` specifying the main verticle (fully qualified class name or script file name)

You can also provide the usual command line arguments that you would pass to `vertx run`:
[source]
----
java -jar my-verticle-fat.jar -cluster -conf myconf.json
java -jar my-verticle-fat.jar -cluster -conf myconf.json -cp path/to/dir/conf/cluster_xml
----

NOTE: Please consult the Maven/Gradle simplest and Maven/Gradle verticle examples in the examples repository for
examples of building applications as fatjars.

A fat jar executes the `run` command, by default.

=== Displaying version of Vert.x
To display the vert.x version, just launch:

[source]
----
vertx version
----

=== Other commands

The `vertx` command line and the `Launcher` also provide other _commands_ in addition to `run` and `version`:

You can create a `bare` instance using:

[source]
----
vertx bare
# or
java -jar my-verticle-fat.jar bare
----

You can also start an application in background using:

[source]
----
java -jar my-verticle-fat.jar start --vertx-id=my-app-name
----

If `my-app-name` is not set, a random id will be generated, and printed on the command prompt. You can pass `run`
options to the `start` command:

[source]
----
java -jar my-verticle-fat.jar start —-vertx-id=my-app-name -cluster
----

Once launched in background, you can stop it with the `stop` command:

[source]
----
java -jar my-verticle-fat.jar stop my-app-name
----

You can also list the vert.x application launched in background using:

[source]
----
java -jar my-verticle-fat.jar list
----

The `start`, `stop` and `list` command are also available from the `vertx` tool. The start` command supports a couple of options:

* `vertx-id` : the application id, uses a random UUID if not set
* `java-opts` : the Java Virtual Machine options, uses the `JAVA_OPTS` environment variable if not set.
* `redirect-output` : redirect the spawned process output and error streams to the parent process streams.

If option values contain spaces, don't forget to wrap the value between `""` (double-quotes).

As the `start` command spawns a new process, the java options passed to the JVM are not propagated, so you **must**
use `java-opts` to configure the JVM (`-X`, `-D`...). If you use the `CLASSPATH` environment variable, be sure it
contains all the required jars (vertx-core, your jars and all the dependencies).

The set of commands is extensible, refer to the <<Extending the vert.x Launcher>> section.

=== Live Redeploy

When developing it may be convenient to automatically redeploy your application upon file changes. The `vertx`
command line tool and more generally the `link:../../apidocs/io/vertx/core/Launcher.html[Launcher]` class offers this feature. Here are some
examples:

[source]
----
vertx run MyVerticle.groovy --redeploy="**/*.groovy" --launcher-class=io.vertx.core.Launcher
vertx run MyVerticle.groovy --redeploy="**/*.groovy,**/*.rb"  --launcher-class=io.vertx.core.Launcher
java io.vertx.core.Launcher run org.acme.MyVerticle --redeploy="**/*.class"  --launcher-class=io.vertx.core
.Launcher -cp ...
----

The redeployment process is implemented as follows. First your application is launched as a background application
(with the `start` command). On matching file changes, the process is stopped and the application is restarted.
This avoids leaks, as the process is restarted.

To enable the live redeploy, pass the `--redeploy` option to the `run` command. The `--redeploy` indicates the
set of file to _watch_. This set can use Ant-style patterns (with `\**`, `*` and `?`). You can specify
several sets by separating them using a comma (`,`). Patterns are relative to the current working directory.

Parameters passed to the `run` command are passed to the application. Java Virtual Machine options can be
configured using `--java-opts`. For instance, to pass the the `conf` parameter or a system property, you need to
use: `--java-opts="-conf=my-conf.json -Dkey=value"`

The `--launcher-class` option determine with with _main_ class the application is launcher. It's generally
`link:../../apidocs/io/vertx/core/Launcher.html[Launcher]`, but you have use you own _main_.

The redeploy feature can be used in your IDE:

* Eclipse - create a _Run_ configuration, using the `io.vertx.core.Launcher` class a _main class_. In the _Program
arguments_ area (in the _Arguments_ tab), write `run your-verticle-fully-qualified-name --redeploy=\**/*.java
--launcher-class=io.vertx.core.Launcher`. You can also add other parameters. The redeployment works smoothly as
Eclipse incrementally compiles your files on save.
* IntelliJ - create a _Run_ configuration (_Application_), set the _Main class_ to `io.vertx.core.Launcher`. In
the Program arguments write: `run your-verticle-fully-qualified-name --redeploy=\**/*.class
--launcher-class=io.vertx.core.Launcher`. To trigger the redeployment, you need to _make_ the project or
the module explicitly (_Build_ menu -> _Make project_).

To debug your application, create your run configuration as a remote application and configure the debugger
using `--java-opts`. However, don't forget to re-plug the debugger after every redeployment as a new process is
created every time.

You can also hook your build process in the redeploy cycle:

[source]
----
java -jar target/my-fat-jar.jar --redeploy="**/*.java" --on-redeploy="mvn package"
java -jar build/libs/my-fat-jar.jar --redeploy="src/**/*.java" --on-redeploy='./gradlew shadowJar'
----

The "on-redeploy" option specifies a command invoked after the shutdown of the application and before the
restart. So you can hook your build tool if it updates some runtime artifacts. For instance, you can launch `gulp`
or `grunt` to update your resources. Don't forget that passing parameters to your application requires the
`--java-opts` param:

[source]
----
java -jar target/my-fat-jar.jar --redeploy="**/*.java" --on-redeploy="mvn package" --java-opts="-Dkey=val"
java -jar build/libs/my-fat-jar.jar --redeploy="src/**/*.java" --on-redeploy='./gradlew shadowJar' --java-opts="-Dkey=val"
----

The redeploy feature also supports the following settings:

* `redeploy-scan-period` : the file system check period (in milliseconds), 250ms by default
* `redeploy-grace-period` : the amount of time (in milliseconds) to wait between 2 re-deployments, 1000ms by default
* `redeploy-termination-period` : the amount of time to wait after having stopped the application (before
launching user command). This is useful on Windows, where the process is not killed immediately. The time is given
in milliseconds. 0 ms by default.

== Cluster Managers

In Vert.x a cluster manager is used for various functions including:

* Discovery and group membership of Vert.x nodes in a cluster
* Maintaining cluster wide topic subscriber lists (so we know which nodes are interested in which event bus addresses)
* Distributed Map support
* Distributed Locks
* Distributed Counters

Cluster managers _do not_ handle the event bus inter-node transport, this is done directly by Vert.x with TCP connections.

The default cluster manager used in the Vert.x distributions is one that uses http://hazelcast.com[Hazelcast] but this
can be easily replaced by a different implementation as Vert.x cluster managers are pluggable.

A cluster manager must implement the interface `link:../../apidocs/io/vertx/core/spi/cluster/ClusterManager.html[ClusterManager]`. Vert.x locates
cluster managers at run-time by using the Java
https://docs.oracle.com/javase/8/docs/api/java/util/ServiceLoader.html[Service Loader] functionality to locate
instances of `link:../../apidocs/io/vertx/core/spi/cluster/ClusterManager.html[ClusterManager]` on the classpath.

If you are using Vert.x at the command line and you want to use clustering you should make sure the `lib` directory
of the Vert.x installation contains your cluster manager jar.

If you are using Vert.x from a Maven or Gradle project just add the cluster manager jar as a dependency of your project.

You can also specify cluster managers programmatically if embedding Vert.x using
`link:../../apidocs/io/vertx/core/VertxOptions.html#setClusterManager-io.vertx.core.spi.cluster.ClusterManager-[setClusterManager]`.

== Logging

Vert.x logs using its internal logging API and supports various logging backends.

The logging backend is selected as follows:

. the backend denoted by the `vertx.logger-delegate-factory-class-name` system property if present or,
. JDK logging when a `vertx-default-jul-logging.properties` file is in the classpath or,
. a backend present in the classpath, in the following order of preference:
.. SLF4J
.. Log4J
.. Log4J2

Otherwise Vert.x defaults to JDK logging.

=== Configuring with the system property

Set the `vertx.logger-delegate-factory-class-name` system property to:

* `io.vertx.core.logging.SLF4JLogDelegateFactory` for SLF4J or,
* `io.vertx.core.logging.Log4j2LogDelegateFactory` for Log4J2 or,
* `io.vertx.core.logging.JULLogDelegateFactory` for JDK logging

=== Automatic configuration

When no `vertx.logger-delegate-factory-class-name` system property is set, Vert.x will try to find
the most appropriate logger:

* use SLF4J when available on the classpath with an actual implementation (i.e. `LoggerFactory.getILoggerFactory()` is not an instance of `NOPLoggerFactory`)
* otherwise use Log4j2 when available on the classpath
* otherwise use JUL

=== Configuring JUL logging

A JUL logging configuration file can be specified in the normal JUL way, by providing a system property named `java.util.logging.config.file` with the value being your configuration file.
For more information on this and the structure of a JUL config file please consult the JDK logging documentation.

Vert.x also provides a slightly more convenient way to specify a configuration file without having to set a system property.
Just provide a JUL config file with the name `vertx-default-jul-logging.properties` on your classpath (e.g. inside your fatjar) and Vert.x will use that to configure JUL.

[[netty-logging]]
=== Netty logging

Netty does not rely on external logging configuration (e.g system properties).
Instead, it implements a logging configuration based on the logging libraries visible from the Netty classes:

* use `SLF4J` library if it is visible
* otherwise use `Log4j` if it is visible
* otherwise use `Log4j2` if it is visible
* otherwise fallback to `java.util.logging`

NOTE: The eagle eyes among you might have noticed that Vert.x follows the same order of preference.

The logger implementation can be forced to a specific implementation by setting Netty's internal logger implementation directly on `io.netty.util.internal.logging.InternalLoggerFactory`:

[source,java]
----
// Force logging to Log4j 2
InternalLoggerFactory.setDefaultFactory(Log4J2LoggerFactory.INSTANCE);
----

=== Troubleshooting

==== SLF4J warning at startup

If, when you start your application, you see the following message:

----
SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
----

It means that you have SLF4J-API in your classpath but no actual binding. Messages logged with SLF4J will be dropped.
You should add a binding to your classpath. Check https://www.slf4j.org/manual.html#swapping to pick a binding and configure it.

Be aware that Netty looks for the SLF4-API jar and uses it by default.

==== Connection reset by peer

If your logs show a bunch of:

----
io.vertx.core.net.impl.ConnectionBase
SEVERE: java.io.IOException: Connection reset by peer
----

It means that the client is resetting the HTTP connection instead of closing it. This message also indicates that you
may have not consumed the complete payload (the connection was cut before you were able to).

include::override/hostname-resolution.adoc[]

[[high_avalibability_and_fail_over]]
== High Availability and Fail-Over

Vert.x allows you to run your verticles with high availability (HA) support. In that case, when a vert.x
instance running a verticle dies abruptly, the verticle is migrated to another vertx instance. The vert.x
instances must be in the same cluster.

=== Automatic failover

When vert.x runs with _HA_ enabled, if a vert.x instance where a verticle runs fails or dies, the verticle is
redeployed automatically on another vert.x instance of the cluster. We call this _verticle fail-over_.

To run vert.x with the _HA_ enabled, just add the `-ha` flag to the command line:

[source]
----
vertx run my-verticle.js -ha
----

Now for HA to work, you need more than one Vert.x instances in the cluster, so let's say you have another
Vert.x instance that you have already started, for example:

[source]
----
vertx run my-other-verticle.js -ha
----

If the Vert.x instance that is running `my-verticle.js` now dies (you can test this by killing the process
with `kill -9`), the Vert.x instance that is running `my-other-verticle.js` will automatic deploy `my-verticle
.js` so now that Vert.x instance is running both verticles.

NOTE: the migration is only possible if the second vert.x instance has access to the verticle file (here
`my-verticle.js`).

IMPORTANT: Please note that cleanly closing a Vert.x instance will not cause failover to occur, e.g. `CTRL-C`
or `kill -SIGINT`

You can also start _bare_ Vert.x instances - i.e. instances that are not initially running any verticles, they
will also failover for nodes in the cluster. To start a bare instance you simply do:

[source]
----
vertx run -ha
----

When using the `-ha` switch you do not need to provide the `-cluster` switch, as a cluster is assumed if you
want HA.

NOTE: depending on your cluster configuration, you may need to customize the cluster manager configuration
(Hazelcast by default), and/or add the `cluster-host` and `cluster-port` parameters.

=== HA groups

When running a Vert.x instance with HA you can also optional specify a _HA group_. A HA group denotes a
logical group of nodes in the cluster. Only nodes with the same HA group will failover onto one another. If
you don't specify a HA group the default group `+++__DEFAULT__+++` is used.

To specify an HA group you use the `-hagroup` switch when running the verticle, e.g.

[source]
----
vertx run my-verticle.js -ha -hagroup my-group
----

Let's look at an example:

In a first terminal:

[source]
----
vertx run my-verticle.js -ha -hagroup g1
----

In a second terminal, let's run another verticle using the same group:

[source]
----
vertx run my-other-verticle.js -ha -hagroup g1
----

Finally, in a third terminal, launch another verticle using a different group:

[source]
----
vertx run yet-another-verticle.js -ha -hagroup g2
----

If we kill the instance in terminal 1, it will fail over to the instance in terminal 2, not the instance in
terminal 3 as that has a different group.

If we kill the instance in terminal 3, it won't get failed over as there is no other vert.x instance in that
group.

=== Dealing with network partitions - Quora

The HA implementation also supports quora. A quorum is the minimum number of votes that a distributed
transaction has to obtain in order to be allowed to perform an operation in a distributed system.

When starting a Vert.x instance you can instruct it that it requires a `quorum` before any HA deployments will
be deployed. In this context, a quorum is a minimum number of nodes for a particular group in the cluster.
Typically you chose your quorum size to `Q = 1 + N/2` where `N` is the number of nodes in the group. If there
are less than `Q` nodes in the cluster the HA deployments will undeploy. They will redeploy again if/when a
quorum is re-attained. By doing this you can prevent against network partitions, a.k.a. _split brain_.

There is more information on quora http://en.wikipedia.org/wiki/Quorum_(distributed_computing)[here].

To run vert.x instances with a quorum you specify `-quorum` on the command line, e.g.

In a first terminal:
[source]
----
vertx run my-verticle.js -ha -quorum 3
----

At this point the Vert.x instance will start but not deploy the module (yet) because there is only one node
in the cluster, not 3.

In a second terminal:
[source]
----
vertx run my-other-verticle.js -ha -quorum 3
----

At this point the Vert.x instance will start but not deploy the module (yet) because there are only two nodes
in the cluster, not 3.

In a third console, you can start another instance of vert.x:

[source]
----
vertx run yet-another-verticle.js -ha -quorum 3
----

Yay! - we have three nodes, that's a quorum. At this point the modules will automatically deploy on all
instances.

If we now close or kill one of the nodes the modules will automatically undeploy on the other nodes, as there
is no longer a quorum.

Quora can also be used in conjunction with ha groups. In that case, quora are resolved for each particular
group.

== Native transports

Vert.x can run with http://netty.io/wiki/native-transports.html[native transports] (when available) on BSD (OSX) and Linux:

include::override/configuring-native.adoc[]

=== Native Linux Transport

You need to add the following dependency in your classpath:

[source,xml]
----
<dependency>
 <groupId>io.netty</groupId>
 <artifactId>netty-transport-native-epoll</artifactId>
 <classifier>linux-x86_64</classifier>
 <!--<version>Should align with netty version that Vert.x uses</version>-->
</dependency>
----

Native on Linux gives you extra networking options:

* `SO_REUSEPORT`
* `TCP_QUICKACK`
* `TCP_CORK`
* `TCP_FASTOPEN`

[source,java]
----
vertx.createHttpServer(new HttpServerOptions()
  .setTcpFastOpen(fastOpen)
  .setTcpCork(cork)
  .setTcpQuickAck(quickAck)
  .setReusePort(reusePort)
);
----

=== Native BSD Transport

You need to add the following dependency in your classpath:

[source,xml]
----
<dependency>
 <groupId>io.netty</groupId>
 <artifactId>netty-transport-native-kqueue</artifactId>
 <classifier>osx-x86_64</classifier>
 <!--<version>Should align with netty version that Vert.x uses</version>-->
</dependency>
----

MacOS Sierra and above are supported.

Native on BSD gives you extra networking options:

* `SO_REUSEPORT`

[source,java]
----
vertx.createHttpServer(new HttpServerOptions().setReusePort(reusePort));
----

=== Domain sockets

Natives provide domain sockets support for servers:

[source,java]
----
vertx.createNetServer().connectHandler(so -> {
  // Handle application
}).listen(SocketAddress.domainSocketAddress("/var/tmp/myservice.sock"));
----

or for http:

[source,java]
----
vertx.createHttpServer().requestHandler(req -> {
  // Handle application
}).listen(SocketAddress.domainSocketAddress("/var/tmp/myservice.sock"), ar -> {
  if (ar.succeeded()) {
    // Bound to socket
  } else {
    ar.cause().printStackTrace();
  }
});
----

As well as clients:

[source,java]
----
NetClient netClient = vertx.createNetClient();

// Only available on BSD and Linux
SocketAddress addr = SocketAddress.domainSocketAddress("/var/tmp/myservice.sock");

// Connect to the server
netClient.connect(addr, ar -> {
  if (ar.succeeded()) {
    // Connected
  } else {
    ar.cause().printStackTrace();
  }
});
----

or for http:

[source,java]
----
HttpClient httpClient = vertx.createHttpClient();

// Only available on BSD and Linux
SocketAddress addr = SocketAddress.domainSocketAddress("/var/tmp/myservice.sock");

// Send request to the server
httpClient.request(new RequestOptions()
  .setServer(addr)
  .setHost("localhost")
  .setPort(8080)
  .setURI("/"))
  .onSuccess(request -> {
    request.send().onComplete(response -> {
      // Process response
    });
  });
----

== Security notes

Vert.x is a toolkit, not an opinionated framework where we force you to do things in a certain way. This gives you
great power as a developer but with that comes great responsibility.

As with any toolkit, it's possible to write insecure applications, so you should always be careful when developing
your application especially if it's exposed to the public (e.g. over the internet).

=== Web applications

If writing a web application it's highly recommended that you use Vert.x-Web instead of Vert.x core directly for
serving resources and handling file uploads.

Vert.x-Web normalises the path in requests to prevent malicious clients from crafting URLs to access resources
outside of the web root.

Similarly for file uploads Vert.x-Web provides functionality for uploading to a known place on disk and does not rely
on the filename provided by the client in the upload which could be crafted to upload to a different place on disk.

Vert.x core itself does not provide such checks so it would be up to you as a developer to implement them yourself.

=== Clustered event bus traffic

When clustering the event bus between different Vert.x nodes on a network, the traffic is sent un-encrypted across the
wire, so do not use this if you have confidential data to send and your Vert.x nodes are not on a trusted network.

=== Standard security best practices

Any service can have potentially vulnerabilities whether it's written using Vert.x or any other toolkit so always
follow security best practice, especially if your service is public facing.

For example you should always run them in a DMZ and with an user account that has limited rights in order to limit
the extent of damage in case the service was compromised.

== Vert.x Command Line Interface API

include::cli.adoc[]

== The vert.x Launcher

The vert.x `link:../../apidocs/io/vertx/core/Launcher.html[Launcher]` is used in _fat jar_ as main class, and by the `vertx` command line
utility. It executes a set of _commands_ such as _run_, _bare_, _start_...

=== Extending the vert.x Launcher

You can extend the set of command by implementing your own `link:../../apidocs/io/vertx/core/spi/launcher/Command.html[Command]` (in Java only):

[source, java]
----
@Name("my-command")
@Summary("A simple hello command.")
public class MyCommand extends DefaultCommand {

 private String name;

 @Option(longName = "name", required = true)
 public void setName(String n) {
   this.name = n;
 }

 @Override
 public void run() throws CLIException {
   System.out.println("Hello " + name);
 }
}
----

You also need an implementation of `link:../../apidocs/io/vertx/core/spi/launcher/CommandFactory.html[CommandFactory]`:

[source, java]
----
public class HelloCommandFactory extends DefaultCommandFactory<HelloCommand> {
 public HelloCommandFactory() {
  super(HelloCommand.class);
 }
}
----

Then, create the `src/main/resources/META-INF/services/io.vertx.core.spi.launcher.CommandFactory` and add a line
indicating the fully qualified name of the factory:

----
io.vertx.core.launcher.example.HelloCommandFactory
----

Builds the jar containing the command. Be sure to includes the SPI file
(`META-INF/services/io.vertx.core.spi.launcher.CommandFactory`).

Then, place the jar containing the command into the classpath of your fat-jar (or include it inside) or in the `lib`
directory of your vert.x distribution, and you would be able to execute:

[source]
----
vertx hello vert.x
java -jar my-fat-jar.jar hello vert.x
----

=== Using the Launcher in fat jars

To use the `link:../../apidocs/io/vertx/core/Launcher.html[Launcher]` class in a _fat-jar_ just set the `Main-Class` of the _MANIFEST_ to
`io.vertx.core.Launcher`. In addition, set the `Main-Verticle` _MANIFEST_ entry to the name of your main verticle.

By default, it executed the `run` command. However, you can configure the default command by setting the
`Main-Command` _MANIFEST_ entry. The default command is used if the _fat jar_ is launched without a command.

=== Sub-classing the Launcher

You can also create a sub-class of `link:../../apidocs/io/vertx/core/Launcher.html[Launcher]` to start your application. The class has been
designed to be easily extensible.

A `link:../../apidocs/io/vertx/core/Launcher.html[Launcher]` sub-class can:

* customize the vert.x configuration in `link:../../apidocs/io/vertx/core/Launcher.html#beforeStartingVertx-io.vertx.core.VertxOptions-[beforeStartingVertx]`
* retrieve the vert.x instance created by the "run" or "bare" command by
overriding `link:../../apidocs/io/vertx/core/Launcher.html#afterStartingVertx-io.vertx.core.Vertx-[afterStartingVertx]`
* configure the default verticle and command with
`link:../../apidocs/io/vertx/core/impl/launcher/VertxCommandLauncher.html#getMainVerticle--[getMainVerticle]` and
`link:../../apidocs/io/vertx/core/impl/launcher/VertxCommandLauncher.html#getDefaultCommand--[getDefaultCommand]`
* add / remove commands using `link:../../apidocs/io/vertx/core/impl/launcher/VertxCommandLauncher.html#register-java.lang.Class-[register]`
and `link:../../apidocs/io/vertx/core/impl/launcher/VertxCommandLauncher.html#unregister-java.lang.String-[unregister]`

=== Launcher and exit code

When you use the `link:../../apidocs/io/vertx/core/Launcher.html[Launcher]` class as main class, it uses the following exit code:

* `0` if the process ends smoothly, or if an uncaught error is thrown
* `1` for general purpose error
* `11` if Vert.x cannot be initialized
* `12` if a spawn process cannot be started, found or stopped. This error code is used by the `start` and
`stop` command
* `14` if the system configuration is not meeting the system requirement (shc as java not found)
* `15` if the main verticle cannot be deployed

== Configuring Vert.x cache

When Vert.x needs to read a file from the classpath (embedded in a fat jar, in a jar form the classpath or a file
that is on the classpath), it copies it to a cache directory. The reason behind this is simple: reading a file
from a jar or from an input stream is blocking. So to avoid to pay the price every time, Vert.x copies the file to
its cache directory and reads it from there every subsequent read. This behavior can be configured.

First, by default, Vert.x uses `$CWD/.vertx` as cache directory. It creates a unique directory inside this one to
avoid conflicts. This location can be configured by using the `vertx.cacheDirBase` system property. For instance
if the current working directory is not writable (such as in an immutable container context), launch your
application with:

[source]
----
vertx run my.Verticle -Dvertx.cacheDirBase=/tmp/vertx-cache
# or
java -jar my-fat.jar vertx.cacheDirBase=/tmp/vertx-cache
----

IMPORTANT: the directory must be **writable**.

When you are editing resources such as HTML, CSS or JavaScript, this cache mechanism can be annoying as it serves
only the first version of the file (and so you won't see your edits if you reload your page). To avoid this
behavior, launch your application with `-Dvertx.disableFileCaching=true`. With this setting, Vert.x still uses
the cache, but always refresh the version stored in the cache with the original source. So if you edit a file
served from the classpath and refresh your browser, Vert.x reads it from the classpath, copies it to the cache
directory and serves it from there. Do not use this setting in production, it can kill your performances.

Finally, you can disable completely the cache by using `-Dvertx.disableFileCPResolving=true`. This setting is not
without consequences. Vert.x would be unable to read any files from the classpath (only from the file system). Be
very careful when using this settings.
